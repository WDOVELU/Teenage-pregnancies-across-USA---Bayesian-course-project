Y_low_1stdiff_pred_1<-diff_to_timeseries(Y_1stdiff[N_train+2,1],Y_low_2nddiff_pred_1)
Y_low_pred_1        <-diff_to_timeseries(Y[N_train+3,1],Y_low_1stdiff_pred_1)
Y_up_2nddiff_pred_1<-diff_to_timeseries(Y_2nddiff[N_train+1,1],apply(resultStSp_1, 2, quantile, p = 0.95))
Y_up_1stdiff_pred_1<-diff_to_timeseries(Y_1stdiff[N_train+2,1],Y_up_2nddiff_pred_1)
Y_up_pred_1        <-diff_to_timeseries(Y[N_train+3,1],Y_up_1stdiff_pred_1)
ggplot(data.frame(x = 26:29,
y = c(Y[26,1],Y_pred_1),
ylow = c(Y[26,1],Y_low_pred_1),
yup = c(Y[26,1],Y_up_pred_1)))+
geom_line(aes(x = x, y = y), lty = 2) + theme_bw() +
geom_line(data = data.frame(Y = Yh[1:26], x = 1:26), aes(x = x, y = Y)) +
geom_ribbon(aes(ymin = ylow, ymax = yup, x = x), alpha = 0.2) +
geom_vline(aes(xintercept = 26), col = 2, lty = 2) +
geom_point(aes(x=c(26,27,28,29), y=Y[26:29,1] )) +
ggtitle("AR1 model - BIRTH rate data Missouri, mixed ages, high schooler")
Y_2nddiff_pred_2<-diff_to_timeseries(Y_2nddiff[N_train+1,2],colMeans(resultStSp_2))
Y_1stdiff_pred_2<-diff_to_timeseries(Y_1stdiff[N_train+2,2],Y_2nddiff_pred_2)
Y_pred_2        <-diff_to_timeseries(Y[N_train+3,2],Y_1stdiff_pred_2)
Y_low_2nddiff_pred_2<-diff_to_timeseries(Y_2nddiff[N_train+1,2],apply(resultStSp_2, 2, quantile, p = 0.05))
Y_low_1stdiff_pred_2<-diff_to_timeseries(Y_1stdiff[N_train+2,2],Y_low_2nddiff_pred_2)
Y_low_pred_2        <-diff_to_timeseries(Y[N_train+3,2],Y_low_1stdiff_pred_2)
Y_up_2nddiff_pred_2<-diff_to_timeseries(Y_2nddiff[N_train+1,2],apply(resultStSp_2, 2, quantile, p = 0.95))
Y_up_1stdiff_pred_2<-diff_to_timeseries(Y_1stdiff[N_train+2,2],Y_up_2nddiff_pred_2)
Y_up_pred_2        <-diff_to_timeseries(Y[N_train+3,2],Y_up_1stdiff_pred_2)
ggplot(data.frame(x = 26:29,
y = c(Y[26,2],Y_pred_2),
ylow = c(Y[26,2],Y_low_pred_2),
yup = c(Y[26,2],Y_up_pred_2)))+
geom_line(aes(x = x, y = y), lty = 2) + theme_bw() +
geom_line(data = data.frame(Y = Y[1:26,2], x = 1:26), aes(x = x, y = Y)) +
geom_ribbon(aes(ymin = ylow, ymax = yup, x = x), alpha = 0.2) +
geom_vline(aes(xintercept = 26), col = 2, lty = 2) +
geom_point(aes(x=c(26,27,28,29), y=Y[26:29,2] )) +
ggtitle("AR1 model - BIRTH rate data Missouri, mixed ages, post high schooler")
# Goodness of fit
llik   <- data.frame(rstan::extract(StSp_model3, "log_lik")[[1]])
p_WAIC_1 <- sum(apply(llik[,1:23], 2, var))
lppd_1   <- sum(apply(llik[,1:23], 2, function(x) log(mean(exp(x)))))
WAIC_1   <- - 2 * lppd_1 + 2 * p_WAIC_1 #91.59127
p_WAIC_2 <- sum(apply(llik[,24:46], 2, var))
lppd_2   <- sum(apply(llik[,24:46], 2, function(x) log(mean(exp(x)))))
WAIC_2   <- - 2 * lppd_2 + 2 * p_WAIC_2 # 136.1916
# MSE for evaluate forcasting performance
MSE_1 <- MSE(Y_pred_1, Y[27:29,1]) # 1.990304
MSE_2 <- MSE(Y_pred_2, Y[27:29,2]) # 5.683792
tab <- rbind(tab,
c(WAIC_1, MSE_1, WAIC_2, MSE_2))
data_StSp <-list(N = N_train,
A = A,
Y = Y_train,
a_sigma2 = 2,
b_sigma2 = 10,
sigma2m0 = 10)
inits <- function()
{
list(phi1 = c(0,0),
phi2 = c(0,0),
beta1 = c(0,0),
beta2 = c(0,0),
beta3 = c(0,0),
m0 = 0,
sigma2 = c(var(Yh),var(Yp)))
}
#                           data = data_StSp,
#                           chains = 2,
#                           iter = 30000,
#                           warmup = 10000,
#                           thin= 20,
#                           seed = 42,
#                           init = inits,
#                           algorithm = 'NUTS')
#
# save(StSp_model, file="ARIMA_2_3_3_mixed_ages_3rd_diff.dat")
load("ARIMA_2_3_3_mixed_ages_3rd_diff.dat")
rstan::traceplot(StSp_model, pars = c("m0", "phi1[1]", "phi1[2]", "phi2[1]", "phi2[2]", "beta1[1]", "beta1[2]", "beta2[1]", "beta2[2]", "beta3[1]", "beta3[2]", "sigma2[1]", "sigma2[2]"), inc_warmup = TRUE)
summary(coda_chain) # quite ugly
# Geweke's convergence diagnostic
coda::geweke.diag(coda_chain, frac1=0.1, frac2=0.5)
# Posterior distributions
plot_post <- StSp_model %>%
rstan::extract(c("m0", "phi1[1]", "phi1[2]", "phi2[1]", "phi2[2]", "beta1[1]", "beta1[2]", "beta2[1]", "beta2[2]", "beta3[1]", "beta3[2]", "sigma2[1]", "sigma2[2]")) %>%
as_tibble() %>%
map_df(as_data_frame, .id = 'param')
# Predictions
# m0 + phi1[a] * Y[t-1,a] + phi2[a] * Y[t-2,a]  + beta1[a] * epsilon[t-1,a] + beta2[a] * epsilon[t-2,a]+beta3[a] * epsilon[t-3,a]
epsilon   <- data.frame(rstan::extract(StSp_model, "epsilon"))
params <- data.frame(rstan::extract(StSp_model, c("m0", "phi1[1]", "phi1[2]", "phi2[1]", "phi2[2]", "beta1[1]", "beta1[2]", "beta2[1]", "beta2[2]", "beta3[1]", "beta3[2]", "sigma2[1]", "sigma2[2]"), perm = T))
resultStSp_1 <- matrix(NA, nrow = nrow(params), ncol = N_test)
# coda
coda_chain <- rstan::As.mcmc.list(StSp_model, pars = c("m0", "phi1[1]", "phi1[2]", "phi2[1]", "phi2[2]", "beta1[1]", "beta1[2]", "beta2[1]", "beta2[2]", "beta3[1]", "beta3[2]", "sigma2[1]", "sigma2[2]"))
# Gelman and rubin's convergence diagnostic
coda::gelman.diag(coda_chain, confidence = 0.95,  autoburnin = TRUE, multivariate=TRUE)
# Autocorrelation and plot
rstan::stan_ac(StSp_model, pars = c("m0", "phi1[1]", "phi1[2]", "phi2[1]", "phi2[2]", "beta1[1]", "beta1[2]", "beta2[1]", "beta2[2]", "beta3[1]", "beta3[2]", "sigma2[1]", "sigma2[2]"))
resultStSp_2 <- matrix(NA, nrow = nrow(params), ncol = N_test)
resultStSp_1[,1] <- apply(cbind(params,epsilon), 1, function(x) rnorm(1, x[1] + x["phi1.1."] * Y_train[N_train,1]+x["phi2.1."] * Y_train[N_train-1,1] + x["beta1.1."] * x["epsilon.23.1"] + x["beta2.1."] * x["epsilon.22.1"] + x["beta3.1."] * x["epsilon.21.1"] , sqrt(x["sigma2.1."])))
resultStSp_2[,1] <- apply(cbind(params,epsilon), 1, function(x) rnorm(1, x[1] + x["phi1.2."] * Y_train[N_train,2]+x["phi2.2."] * Y_train[N_train-1,2] + x["beta1.2."] * x["epsilon.23.2"] + x["beta2.2."] * x["epsilon.22.2"] + x["beta3.2."] * x["epsilon.21.2"] , sqrt(x["sigma2.2."])))
resultStSp_2[,2] <- apply(cbind(params,epsilon, resultStSp_2[,1]), 1, function(x) rnorm(1, x[1] + x["phi1.2."] * x[60]+x["phi2.2."] * Y_train[N_train,2] + x["beta1.2."] * 0  + x["beta2.2."] * x["epsilon.23.2"] + x["beta3.2."] * x["epsilon.22.2"] , sqrt(x["sigma2.2."])))
resultStSp_1[,3] <- apply(cbind(params,epsilon, resultStSp_1[,1], resultStSp_1[,2]), 1, function(x) rnorm(1, x[1] + x["phi1.1."] * x[61]+x["phi2.1."] * x[60] + x["beta1.1."] * 0  + x["beta2.1."] * 0 + x["beta3.1."] * x["epsilon.23.1"] , sqrt(x["sigma2.1."])))
plot_post %>%
ggplot(aes(value, fill = param)) +
geom_density() +
facet_wrap(~param, scales = 'free') +
scale_fill_locuszoom() +
theme_minimal() +
theme(legend.position="none")
resultStSp_2[,3] <- apply(cbind(params,epsilon, resultStSp_2[,1], resultStSp_1[,2]), 1, function(x) rnorm(1, x[1] + x["phi1.2."] * x[61]+x["phi2.2."] * x[60] + x["beta1.2."] * 0  + x["beta2.2."] * 0 + x["beta3.2."] * x["epsilon.23.2"] , sqrt(x["sigma2.2."])))
ggplot(data.frame(x = (N_train) :(N_train + N_test),
y = c(Y_train[N_train,2],colMeans(resultStSp_2)),
ylow = c(Y_train[N_train,2],apply(resultStSp_2, 2, quantile, p = 0.05)),
yup = c(Y_train[N_train,2],apply(resultStSp_2, 2, quantile, p = 0.95)))) +
geom_line(aes(x = x, y = y), lty = 2) + theme_bw() +
geom_line(data = data.frame(Y = Y_train[,2], x = 1:N_train), aes(x = x, y = Y)) +
geom_ribbon(aes(ymin = ylow, ymax = yup, x = x), alpha = 0.2) +
geom_vline(aes(xintercept = N_train), col = 2, lty = 2) +
geom_point(aes(x=(N_train) :(N_train + N_test), y=c(Y_train[N_train,2],Y_test[,2]) )) +
ggtitle("AR1 model - Third order differences data Missouri, mixed ages, post high schooler")
Y_2nddiff_pred_1<-diff_to_timeseries(Y_2nddiff[N_train+1,1],colMeans(resultStSp_1))
Y_1stdiff_pred_1<-diff_to_timeseries(Y_1stdiff[N_train+2,1],Y_2nddiff_pred_1)
Y_pred_1        <-diff_to_timeseries(Y[N_train+3,1],Y_1stdiff_pred_1)
# for 2nd year prediction, we don't have true value for 1st prediction.so we cannot compute the eplison_t-1 and I just set it as 0;
resultStSp_1[,2] <- apply(cbind(params,epsilon, resultStSp_1[,1]), 1, function(x) rnorm(1, x[1] + x["phi1.1."] * x[60]+x["phi2.1."] * Y_train[N_train,1] + x["beta1.1."] * 0  + x["beta2.1."] * x["epsilon.23.1"] + x["beta3.1."] * x["epsilon.22.1"] , sqrt(x["sigma2.1."])))
Y_low_2nddiff_pred_1<-diff_to_timeseries(Y_2nddiff[N_train+1,1],apply(resultStSp_1, 2, quantile, p = 0.05))
Y_low_1stdiff_pred_1<-diff_to_timeseries(Y_1stdiff[N_train+2,1],Y_low_2nddiff_pred_1)
Y_low_pred_1        <-diff_to_timeseries(Y[N_train+3,1],Y_low_1stdiff_pred_1)
Y_up_2nddiff_pred_1<-diff_to_timeseries(Y_2nddiff[N_train+1,1],apply(resultStSp_1, 2, quantile, p = 0.95))
Y_up_1stdiff_pred_1<-diff_to_timeseries(Y_1stdiff[N_train+2,1],Y_up_2nddiff_pred_1)
Y_up_pred_1        <-diff_to_timeseries(Y[N_train+3,1],Y_up_1stdiff_pred_1)
Y_2nddiff_pred_2<-diff_to_timeseries(Y_2nddiff[N_train+1,2],colMeans(resultStSp_2))
Y_1stdiff_pred_2<-diff_to_timeseries(Y_1stdiff[N_train+2,2],Y_2nddiff_pred_2)
ggplot(data.frame(x = (N_train) :(N_train + N_test),
y = c(Y_train[N_train,1],colMeans(resultStSp_1)),
ylow = c(Y_train[N_train,1],apply(resultStSp_1, 2, quantile, p = 0.05)),
yup = c(Y_train[N_train,1],apply(resultStSp_1, 2, quantile, p = 0.95)))) +
geom_line(aes(x = x, y = y), lty = 2) + theme_bw() +
geom_line(data = data.frame(Y = Y_train[,1], x = 1:N_train), aes(x = x, y = Y)) +
geom_ribbon(aes(ymin = ylow, ymax = yup, x = x), alpha = 0.2) +
geom_vline(aes(xintercept = N_train), col = 2, lty = 2) +
geom_point(aes(x=(N_train) :(N_train + N_test), y=c(Y_train[N_train,1],Y_test[,1]) )) +
ggtitle("AR1 model - Third order differences data Missouri, mixed ages, high schooler")
ggplot(data.frame(x = 26:29,
y = c(Y[26,1],Y_pred_1),
ylow = c(Y[26,1],Y_low_pred_1),
yup = c(Y[26,1],Y_up_pred_1)))+
geom_line(aes(x = x, y = y), lty = 2) + theme_bw() +
geom_line(data = data.frame(Y = Yh[1:26], x = 1:26), aes(x = x, y = Y)) +
geom_ribbon(aes(ymin = ylow, ymax = yup, x = x), alpha = 0.2) +
geom_vline(aes(xintercept = 26), col = 2, lty = 2) +
geom_point(aes(x=c(26,27,28,29), y=Y[26:29,1] )) +
ggtitle("AR1 model - BIRTH rate data Missouri, mixed ages, high schooler")
Y_pred_2        <-diff_to_timeseries(Y[N_train+3,2],Y_1stdiff_pred_2)
Y_low_2nddiff_pred_2<-diff_to_timeseries(Y_2nddiff[N_train+1,2],apply(resultStSp_2, 2, quantile, p = 0.05))
Y_low_1stdiff_pred_2<-diff_to_timeseries(Y_1stdiff[N_train+2,2],Y_low_2nddiff_pred_2)
Y_low_pred_2        <-diff_to_timeseries(Y[N_train+3,2],Y_low_1stdiff_pred_2)
Y_up_2nddiff_pred_2<-diff_to_timeseries(Y_2nddiff[N_train+1,2],apply(resultStSp_2, 2, quantile, p = 0.95))
Y_up_1stdiff_pred_2<-diff_to_timeseries(Y_1stdiff[N_train+2,2],Y_up_2nddiff_pred_2)
Y_up_pred_2        <-diff_to_timeseries(Y[N_train+3,2],Y_up_1stdiff_pred_2)
ggplot(data.frame(x = 26:29,
y = c(Y[26,2],Y_pred_2),
ylow = c(Y[26,2],Y_low_pred_2),
yup = c(Y[26,2],Y_up_pred_2)))+
geom_line(aes(x = x, y = y), lty = 2) + theme_bw() +
geom_line(data = data.frame(Y = Y[1:26,2], x = 1:26), aes(x = x, y = Y)) +
geom_ribbon(aes(ymin = ylow, ymax = yup, x = x), alpha = 0.2) +
geom_vline(aes(xintercept = 26), col = 2, lty = 2) +
geom_point(aes(x=c(26,27,28,29), y=Y[26:29,2] )) +
ggtitle("AR1 model - BIRTH rate data Missouri, mixed ages, post high schooler")
# Goodness of fit
llik   <- data.frame(rstan::extract(StSp_model, "log_lik")[[1]])
p_WAIC_1 <- sum(apply(llik[,4:23], 2, var))
lppd_1   <- sum(apply(llik[,4:23], 2, function(x) log(mean(exp(x)))))
WAIC_1   <- - 2 * lppd_1 + 2 * p_WAIC_1   ##73.4827
p_WAIC_2 <- sum(apply(llik[,27:46], 2, var))
lppd_2   <- sum(apply(llik[,27:46], 2, function(x) log(mean(exp(x)))))
WAIC_2   <- - 2 * lppd_2 + 2 * p_WAIC_2   ##104.6212
# MSE for evaluate forcasting performance
MSE_1 <- MSE(Y_pred_1, Y[27:29,1])  #0.1279609
MSE_2 <- MSE(Y_pred_2, Y[27:29,2])  #2.797991
tab <- rbind(tab,
c(WAIC_1, MSE_1, 0.03884597, WAIC_2, MSE_2, 0.03202568))
TAB <- data.frame(tab)
colnames(TAB) <- c("WAIC High", "MSE High", "WAIC PostHigh", "MSE PostHigh")
row.names(TAB) <- c("ARIMA(1,3,0) 1st version", "ARIMA(1,3,0) 2nd version", "ARIMA(1,3,0) 3rd version", "ARIMA(2,3,3)")
TAB
#---------------------------- TEST ----------------------------
#              Mean     SD Naive SE Time-series SE
# m0         0.1228 0.3502 0.007830       0.007827      good
# phi[1]    -0.8385 0.1377 0.003080       0.003122      good
# phi[2]    -0.5716 0.1828 0.004087       0.004058      good
# sigma2[1]  3.3809 1.0522 0.023527       0.025329      ok
# sigma2[2] 16.6686 5.1460 0.115067       0.109909      ok
set.seed(1441)
state <- c("Alabama", "Alaska", "Arizona", "Arkansas", "California", "Colorado",
"Connecticut", "Delaware", "District of Columbia", "Florida", "Georgia",
"Hawaii", "Idaho", "Illinois", "Indiana", "Iowa", "Kansas", "Kentucky",
"Louisiana", "Maine", "Maryland", "Massachusetts", "Michigan", "Minnesota",
"Mississippi", "Montana", "Nebraska", "Nevada", "New Hampshire", "New Jersey",
"New Mexico", "New York", "North Carolina", "North Dakota", "Ohio", "Oklahoma",
"Oregon", "Pennsylvania", "Rhode Island", "South Carolina", "South Dakota",
"Tennessee", "Texas", "Utah", "Vermont", "Virginia", "Washington", "West Virginia",
"Wisconsin", "Wyoming")
N_try = 25
p <- c(0.1228, -0.8385, -0.5716, 3.3809, 16.6686)
load("mse_usa.dat")
load("ts_high_all.dat")
load("ts_post_all.dat")
load("ts_high_diff.dat")
load("ts_post_diff.dat")
load("ts_high_pred.dat")
load("ts_post_pred.dat")
mse_tot
m_high <- min(mse_tot[,1]) #Virginia
m_post <- min(mse_tot[,2]) #Ohio
# Minimum mse:
ggplot(data.frame(x = 1:26), y = ts_high_pred[mse_tot[,1] == m_high,]) +
geom_line(data = data.frame(Y = ts_high_pred[mse_tot[,1] == m_high,], x = 1:26),
aes(x = x, y = Y, col = "Simulated data"), lty = 2) +
geom_line(data = data.frame(Y = ts_high_diff[mse_tot[,1] == m_high,], x = 1:26),
aes(x = x, y = Y, col = "Real data")) + theme_bw() + scale_color_discrete(name="Legend") +
ggtitle("Forecasting on Virginia State for Highschool")
ggplot(data.frame(x = 1:26), y = ts_post_diff[mse_tot[,2] == m_post,]) +
geom_line(data = data.frame(Y = ts_post_diff[mse_tot[,2] == m_post,], x = 1:26),
aes(x = x, y = Y, col = "Simulated data"), lty = 2) +
geom_line(data = data.frame(Y = ts_post_pred[mse_tot[,2] == m_post,], x = 1:26),
aes(x = x, y = Y, col = "Real data")) + theme_bw() + scale_color_discrete(name="Legend") +
ggtitle("Forecasting on Ohio State for Post-Highschool")
# BAD mse but state is close to missouri
ggplot(data.frame(x = 1:26), y = ts_post_diff[state == "Nebraska",]) +
geom_line(data = data.frame(Y = ts_post_diff[state == "Nebraska",], x = 1:26),
aes(x = x, y = Y), lty = 2, col = "red") +
geom_line(data = data.frame(Y = ts_post_pred[state == "Nebraska",], x = 1:26),
aes(x = x, y = Y), col = "blue") + theme_bw() +
ggtitle("Forecasting on Nebraska State for Post-Highschool")
# GOOD mse but state is far away from missouri
ggplot(data.frame(x = 1:26), y = ts_high_pred[state == "Oregon",]) +
geom_line(data = data.frame(Y = ts_high_pred[state == "Oregon",], x = 1:26),
aes(x = x, y = Y), lty = 2, col = "red") +
geom_line(data = data.frame(Y = ts_high_diff[state == "Oregon",], x = 1:26),
aes(x = x, y = Y), col = "blue") + theme_bw() +
ggtitle("Forecasting on Oregon State for Highschool")
# the most weird mse
ggplot(data.frame(x = 1:26), y = ts_high_pred[state == "District of Columbia",]) +
geom_line(data = data.frame(Y = ts_high_pred[state == "District of Columbia",], x = 1:26),
aes(x = x, y = Y), lty = 2, col = "red") +
geom_line(data = data.frame(Y = ts_high_diff[state == "District of Columbia",], x = 1:26),
aes(x = x, y = Y), col = "blue") + theme_bw() +
ggtitle("Forecasting on State District of Columbia for Highschool")
#-------------------------------
data <- t(ts_high_all)
length(state)
colnames(data) <- state
write.csv(data, 'highschool_ts.csv')
data_diff <- t(ts_high_diff)
colnames(data_diff) <- state
write.csv(data_diff, 'highschool_ts_diff.csv')
graphics.off()
rm(list=ls())
#### Spatio-Temporal model for Highschool age
library(CARBayesST)
library(spdep)
library(maptools)
library(sp)
library(CARBayesdata)
library(USAboundaries)
library(sf)
library(dplyr)
mydata <- read_excel("data.xlsx")
BIRTH_data <- data.frame(mydata)
# removing isolated States
birthdata_hs <- subset(BIRTH_data, BIRTH_data$Age.Group..Years. == "15-17 years")
birthdata_hs <- subset(birthdata_hs, birthdata_hs$State != "Total U.S.")
birthdata_hs <- subset(birthdata_hs, birthdata_hs$State != "Hawaii")
birthdata_hs <- subset(birthdata_hs, birthdata_hs$State != "Alaska")
birthdata_hs <- birthdata_hs[,c(2,1,5,4)]
### Construct the SpatialPolygonsDataFrame
require(maps)
require(sp)
require(maptools)
require(tmap)
require(cartogram)
mydata <- data.frame(lapply(mydata, function(v) {
if (is.character(v)) return(tolower(v))
else return(v)
}))
# Lower case letters for all states, in order to merge them with the map
mydata <- birthdata_hs
# Get a SpatialPolygonsDataFrame of US states
usa <- map("state", fill = TRUE)
IDs <- sapply(strsplit(usa$names, ":"), function(x) x[1])
usa <- map2SpatialPolygons(usa, IDs=IDs, proj4string=CRS("+proj=longlat +datum=WGS84"))
usa <- SpatialPolygonsDataFrame(usa,
data = data.frame(unique(IDs),
row.names = unique(IDs)) )
usa@data = data.frame(usa@data, mydata[match(usa@data[,'unique.IDs.'], mydata[,'State' ]),])
usa.data.combined = usa
# remove NAs from the dataset
usa.data.combined@data <- usa.data.combined@data[complete.cases(usa.data.combined@data), ]
spplot(usa.data.combined[, "State.Rate"], main = "Birth rate" )
### Constuct binary neighbourhood matrix W
W.nb <- poly2nb(usa.data.combined, row.names = unique(IDs)) # neighbourhood
W <- nb2mat(W.nb, style = "B")
dim(W) # matrix of dimension 49 x 49
W[7:15,7:15]
W_nodoc <- W[c(-8),c(-8)]
W_nodoc[7:15,7:15]
K<-49 # number of states
N<-29 # number of years
### Third order differences - Stationnarisation and fixing the state order which was not always the same
dif3rate <- rep(0,K*(N-3)) # vector of third differences of State.Rate
shifrate <- rep(0,K*(N-3)) # State.Rate shifted by 3 years
fix_rate <- rep(0,K*N)
states <- mydata$State[1:49]
for (i in c(1:49))
{
state <- states[i]
state_subset <- subset(mydata, mydata$State == state)
rate <- state_subset$State.Rate
dif3 <- diff(rate,diff=3)
shif <- rate[c(4:29)]
for (j in c(0:25))
{
dif3rate[i + K*j] <- dif3[j+1]
shifrate[i + K*j] <- shif[j+1]
}
for (j in c(0:28))
{
fix_rate[i + K*j] <- rate[j+1]
}
}
years <- c(rep(1990,49),rep(1991,49),rep(1992,49),rep(1993,49),rep(1994,49),rep(1995,49)
,rep(1996,49),rep(1997,49),rep(1998,49),rep(1999,49),rep(2000,49),rep(2001,49)
,rep(2002,49),rep(2003,49),rep(2004,49),rep(2005,49),rep(2006,49),rep(2007,49)
,rep(2008,49),rep(2009,49),rep(2010,49),rep(2011,49),rep(2012,49),rep(2013,49)
,rep(2014,49),rep(2015,49),rep(2016,49),rep(2017,49),rep(2018,49))
shif_years <- years[c((49*3+1):(49*N))] # years vector, without the first three years
mydata_staz <- data.frame(rep(states,26),shif_years,dif3rate,shifrate) # new dataframe
mydata_fix <- data.frame(rep(states,29),years,fix_rate)
### Moran I for each year for raw Rates.
moranI_years <- rep(0,29)
for (i in c(1990:2018))
{
moran_subset <- subset(mydata_fix, years == i)
mt <- moran.test(moran_subset$fix_rate,nb2listw(W.nb,style = "B"))
moranI_years[i-1989] <- mt$estimate[1]
}
plot(c(1990:2018),moranI_years,main = 'Morans I over Years for raw data',
xlab='Years', ylab='Morans I',ylim = c(-0.1,0.6), pch = 19, col='blue')
abline(h=0, pch=10, col="black", lwd=2, lty=2)
### Moran I for each year for 3rd differences
moranI_years <- rep(0,26)
for (i in c (1993:2018))
{
moran_subset <- subset(mydata_staz, mydata$Year == i)
mt <- moran.test(moran_subset$dif3rate,nb2listw(W.nb,style = "B"))
moranI_years[i-1992] <- mt$estimate[1]
}
plot(c(1993:2018),moranI_years, main = 'Morans I over Years for stationarize data',
xlab='Years', ylab='Morans I',ylim = c(-0.1,0.6), pch = 19, col='red')
abline(h=0, pch=10, col="black", lwd=2, lty=2)
### How "far" should we reach for  neighbours
library(rgeos)
centroids <- gCentroid(usa,byid=T)
nb_knn7 <- knn2nb((knearneigh(centroids,k=7)))
sp_corG <- sp.correlogram(nb_knn7,usa.data.combined@data$State.Rate, order = 7,
zero.policy = TRUE, style = 'B', method = 'I')
plot(sp_corG, main = 'Spatial correlogram for Birth rates in States', ylab="Morans'I")
### Spatial modelling with CARBayesST : ST.CARar on Highschool raw data
set.seed(1200)
formula1 <- fix_rate ~ fix_rate
chain1 <- ST.CARar(formula = formula1, family = "gaussian",
data = mydata_fix, W = W, burnin = 20000, n.sample = 220000,
thin = 100)
x11()
# Posterion inference
print(chain1)
########################################################################
# install.packages("USAboundaries")
# install.packages("CARBayesST")
library(CARBayesST)
library(spdep)
library(maptools)
library(sp)
library(CARBayesdata)
library(USAboundaries)
library(sf)
library(dplyr)
library(ggplot2)
library(MLmetrics)
# setwd("G:/Bayesian_project_final/2_CARBayesST")
library(readxl)
mydata <- read_excel("datajay.xlsx")
getwd()
mydata <- read_excel("data.xlsx")
BIRTH_data <- data.frame(mydata)
# removing isolated States
birthdata_hs <- subset(BIRTH_data, BIRTH_data$Age.Group..Years. == "15-17 years")
birthdata_hs <- subset(birthdata_hs, birthdata_hs$State != "Total U.S.")
birthdata_hs <- subset(birthdata_hs, birthdata_hs$State != "Hawaii")
birthdata_hs <- subset(birthdata_hs, birthdata_hs$State != "Alaska")
birthdata_hs <- birthdata_hs[,c(2,1,5,4)]
### Construct the SpatialPolygonsDataFrame
require(maps)
require(sp)
require(maptools)
require(tmap)
require(cartogram)
# Lower case letters for all states, in order to merge them with the map
mydata <- birthdata_hs
mydata <- data.frame(lapply(mydata, function(v) {
if (is.character(v)) return(tolower(v))
else return(v)
}))
# Get a SpatialPolygonsDataFrame of US states
usa <- map("state", fill = TRUE)
IDs <- sapply(strsplit(usa$names, ":"), function(x) x[1])
usa <- map2SpatialPolygons(usa, IDs=IDs, proj4string=CRS("+proj=longlat +datum=WGS84"))
usa <- SpatialPolygonsDataFrame(usa,
data = data.frame(unique(IDs),
row.names = unique(IDs)) )
usa@data = data.frame(usa@data, mydata[match(usa@data[,'unique.IDs.'], mydata[,'State' ]),])
usa.data.combined = usa
# remove NAs from the dataset
usa.data.combined@data <- usa.data.combined@data[complete.cases(usa.data.combined@data), ]
spplot(usa.data.combined[, "State.Rate"], main = "Birth rate" )
W <- nb2mat(W.nb, style = "B")
dim(W) # matrix of dimension 49 x 49
### Constuct binary neighbourhood matrix W
W.nb <- poly2nb(usa.data.combined, row.names = unique(IDs)) # neighbourhood
W[7:15,7:15]
W_nodoc <- W[c(-8),c(-8)]
W_nodoc[7:15,7:15]
K<-49 # number of states
N<-29 # number of years
### Third order differences - Stationnarisation and fixing the state order which was not always the same
dif3rate <- rep(0,K*(N-3)) # vector of third differences of State.Rate
shifrate <- rep(0,K*(N-3)) # State.Rate shifted by 3 years
fix_rate <- rep(0,K*N)
states <- mydata$State[1:49]
for (i in c(1:49))
{
state <- states[i]
state_subset <- subset(mydata, mydata$State == state)
rate <- state_subset$State.Rate
dif3 <- diff(rate,diff=3)
shif <- rate[c(4:29)]
for (j in c(0:25))
{
dif3rate[i + K*j] <- dif3[j+1]
shifrate[i + K*j] <- shif[j+1]
}
for (j in c(0:28))
{
fix_rate[i + K*j] <- rate[j+1]
}
}
years <- c(rep(1990,49),rep(1991,49),rep(1992,49),rep(1993,49),rep(1994,49),rep(1995,49)
,rep(1996,49),rep(1997,49),rep(1998,49),rep(1999,49),rep(2000,49),rep(2001,49)
,rep(2002,49),rep(2003,49),rep(2004,49),rep(2005,49),rep(2006,49),rep(2007,49)
,rep(2008,49),rep(2009,49),rep(2010,49),rep(2011,49),rep(2012,49),rep(2013,49)
,rep(2014,49),rep(2015,49),rep(2016,49),rep(2017,49),rep(2018,49))
shif_years <- years[c((49*3+1):(49*N))] # years vector, without the first three years
mydata_staz <- data.frame(rep(states,26),shif_years,dif3rate,shifrate) # new dataframe
mydata_fix <- data.frame(rep(states,29),years,fix_rate)
### Moran I for each year for raw Rates.
moranI_years <- rep(0,29)
for (i in c(1990:2018))
{
moran_subset <- subset(mydata_fix, years == i)
mt <- moran.test(moran_subset$fix_rate,nb2listw(W.nb,style = "B"))
moranI_years[i-1989] <- mt$estimate[1]
}
plot(c(1990:2018),moranI_years,main = 'Morans I over Years for raw data',
xlab='Years', ylab='Morans I',ylim = c(-0.1,0.6), pch = 19, col='blue')
abline(h=0, pch=10, col="black", lwd=2, lty=2)
### Moran I for each year for 3rd differences
moranI_years <- rep(0,26)
for (i in c (1993:2018))
{
moran_subset <- subset(mydata_staz, mydata$Year == i)
mt <- moran.test(moran_subset$dif3rate,nb2listw(W.nb,style = "B"))
moranI_years[i-1992] <- mt$estimate[1]
}
plot(c(1993:2018),moranI_years, main = 'Morans I over Years for stationarize data',
xlab='Years', ylab='Morans I',ylim = c(-0.1,0.6), pch = 19, col='red')
abline(h=0, pch=10, col="black", lwd=2, lty=2)
### How "far" should we reach for  neighbours
library(rgeos)
centroids <- gCentroid(usa,byid=T)
nb_knn7 <- knn2nb((knearneigh(centroids,k=7)))
sp_corG <- sp.correlogram(nb_knn7,usa.data.combined@data$State.Rate, order = 7,
zero.policy = TRUE, style = 'B', method = 'I')
plot(sp_corG, main = 'Spatial correlogram for Birth rates in States', ylab="Morans'I")
### Spatial modelling with CARBayesST : ST.CARar on Highschool raw data
set.seed(1200)
formula1 <- fix_rate ~ fix_rate
chain1 <- ST.CARar(formula = formula1, family = "gaussian",
data = mydata_fix, W = W, burnin = 20000, n.sample = 220000,
thin = 100)
x11()
# Posterion inference
print(chain1)
library(LaplacesDemon)
# setwd("G:/Bayesian_project_final/2_CARBayesST")
library(readxl)
mydata <- read_excel("data.xlsx")
ggplot(data.frame(x = 1990:2018, y = ohio$ohioNA, ylow = ohio$low, yup = ohio$high) ) +
geom_line(aes(x = x, y = y), lty = 2, col = "red") + theme_bw() +
geom_line(data = data.frame(Y = ohio$fix_rate, x = 1990:2018), aes(x = x, y = Y), col = "blue") +
geom_ribbon(aes(ymin = ylow, ymax = yup, x = x), alpha = 0.1, col="lightblue") +
ggtitle("Observed vs sampled Ohio Birth rate values")
## Putting last 3 years NA in Missouri and plot the posterior inferences
mydata_fixNA3<-mydata_fix
